---
layout: post
title:  "Presto in 2019: Year in Review"
author: Martin Traverso
excerpt_separator: <!--more-->
---

What a great year for the Presto community! We started with the year with the launch of the 
[Presto Software Foundation]({% post_url 2019-01-31-presto-software-foundation-launch %}), 
with the long term goal of ensuring the project remains collaborative, open and independent from 
any corporate interest, for years to come.

Since then, the community around Presto has grown and consolidated. We’ve seen contributions 
from more than 120 people across over 20 companies. Every week, 280 users and developers 
interact in the project’s [Slack channel](/slack.html). We'd like to take the opportunity to thank 
everyone that contributed the project in one way or another. Presto wouldn't be what it is without your 
help.

With the collaboration of companies such as [Starburst](https://starburstdata.com), [Qubole](https://qubole.com), 
[Varada](https://varada.io), [Twitter](https://twitter.com), [ARM Treasure Data](https://www.treasuredata.com),
[Wix](https://wix.com), [Red Hat](https://www.redhat.com), and the [Big Things community](https://www.meetup.com/Big-things-are-happening-here/),
we ran several Presto summits across the world: 
* [Tel Aviv, Israel, April 2019]({% post_url 2019-05-03-Presto-Conference-Israel %})
* [San Francisco, USA, June 2019]({% post_url 2019-05-17-Presto-Summit %})
* [Tokyo, Japan, July 2019]({% post_url 2019-07-11-report-for-presto-conference-tokyo %}) 
* [Bangalore, India, September, 2019]({% post_url 2019-09-05-Presto-Summit-Bangalore %})
* [New York, USA, December 2019](https://www.starburstdata.com/technical-blog/nyc-presto-summit-recap/) 

All these events were a huge success and brought thousands of Presto users, contributors and other community members together to 
share their knowledge and experiences.

The project has been more active than ever. We completed 28 releases comprised of more than 2850 
commits in over 1500 pull requests. Of course, that alone is not a good measure of progress, so 
let’s take a closer look at everything that went in. And there is a lot to look at!

<!--more-->

## Language Features

* [`FETCH FIRST n ROWS [ONLY | WITH TIES]`](/docs/current/sql/select.html#limit-or-fetch-first-clauses) 
  standard syntax. The `WITH TIES` clause is particularly useful when some of the rows have the same 
  value for the columns being used to order the results of a query. Consider a case where you want to 
  list top 5 students with highest score on an exam. If the 6th person has the same score as the 5th, you 
  want to know this as well, instead of getting an arbitrary and non-deterministic result:

  ```sql
  SELECT student_name, score
  FROM student JOIN exam_result USING (student_id)
  ORDER BY score
  FETCH FIRST 5 ROWS WITH TIES
  ```

* [`OFFSET`](/docs/current/sql/select.html#offset-clause) syntax, which is especially useful in ad-hoc queries.
* [`COMMENT ON <table>`](/docs/current/sql/comment.html) syntax to 
  set or remove table comments. Comments can be shown via `DESCRIBE`
  or the new `system.metadata.table_comments` table.
* Support for `LATERAL` in the context of an outer join.
* Support for `UNNEST` in the context of `LEFT JOIN`. With this feature, it is now possible 
  to preserve the outer row when the array contains zero elements or is `NULL`. Most common usages
  of `UNNEST` in a `CROSS JOIN` should actually be using this form.
	
  ```sql	
  SELECT * FROM t LEFT JOIN UNNEST(t.a) u (v) ON true
  ```

* `IGNORE NULLS` clause for window functions. This is useful when combined with 
  functions such as `lead`, `lag`, `first_value`, `last_value` and `nth_value` if the dataset contains nulls.
* `ROW` expansion using `.*` operator.
* [`CREATE SCHEMA`](/docs/current/sql/create-schema.html) syntax and support 
  in various connectors (Hive, Iceberg, MySQL, PostgreSQL, Redshift, SQL Server, Phoenix).
* Support for correlated subqueries containing `LIMIT` or `ORDER BY`+`LIMIT`.
* Subscript operator to access `ROW` type fields by index. This greatly improves usability 
  and readability of queries when dealing with `ROW` types containing anonymous fields.
  
    ![](/assets/blog/2019-review/row-ordinal.png)

## Query Engine

* Generalize conditional, lazy loading and processing (a.k.a., Late Materialization) beyond 
  Table Scan, Filter and Projection to support Join, Window, TopN and SemiJoin operators. This can dramatically 
  reduce latency, CPU and I/O for highly selective queries. This is one of the most important performance 
  optimizations in recent times and we will be blogging about this more in coming weeks.
* [Unwrap cast/predicate pushdown]({% post_url 2019-05-21-optimizing-the-casts-away %}) optimizations.
* Connector pushdown during planning for operations such as limit, table sample, or projections. This allows 
  connectors to optimize how data is accessed before it's provided to the Presto engine for further processing. 
* [Dynamic filtering]({% post_url 2019-06-30-dynamic-filtering %}).
* Cost-Based Optimizer can now consider [estimated query peak memory]({{site.github_repo_url}}/pull/247) 
  footprint. This is especially useful for optimizing bigger queries, where not all parts of the query can 
  be run concurrently.
* Improved handling of [projections]({{site.github_repo_url}}/pull/1431), 
  [aggregations]({{site.github_repo_url}}/pull/864) and [cross joins]({{site.github_repo_url}}/pull/1359) 
  in cost based optimizer.
* Improved accounting and reporting of physical and network data read or transmitted during query processing.    

## Performance

* [10x performance improvement for `UNNEST`]({% post_url 2019-08-23-unnest-operator-performance-enhancements %}).
* 2-7x improvement in performance of [ORC decoders]({% post_url 2019-04-23-even-faster-orc %}), resulting in a 
  10% global CPU improvement for the TPC-DS benchmark.
* Improvements when reading small Parquet files, files with large number of columns, or files with small row
  groups. We found this very useful, for example, when working with data exported from Snowflake.
* Support for new ORC bloom filters.
* Remove [redundant `ORDER BY`]({% post_url 2019-06-03-redundant-order-by %}) clauses.
* Improvements for [`IN` and `NOT-IN`]({% post_url 2019-06-03-redundant-order-by %}) with subquery expressions (i.e., semijoin).
* Huge performance improvements when [reading from `information_schema`]({{site.github_repo_url}}/pull/1329).
* Reduce query latency and Hive metastore load, for both `SELECT` and `INSERT` queries.
* Improve metadata handling during planning. This can result in dramatic improvements in latency, 
  especially for connectors such as MySQL, PostgreSQL, Redshift, SQL Server, etc. Some queries like 
  `SHOW SCHEMAS` or `SHOW TABLES` that could take several minutes to complete now finish in a few seconds.
* Improved stability, performance, and security when spilling is enabled.  

## Functions

* [`combinations`](/docs/current/functions/array.html#combinations)
* [`format`](/docs/current/functions/conversion.html#format)
* [`UUID` type](/docs/current/functions/uuid.html) and related functions.
* [`all_match`](/docs/current/functions/array.html#all_match),
  [`any_match`](/docs/current/functions/array.html#any_match) and 
  [`none_match`](/docs/current/functions/array.html#none_match).
* Support flexible aggregation with lambda expressions using
    [`reduce_agg`](/docs/current/functions/aggregate.html#reduce_agg). 
* New date and time functions: [`last_day_of_month`](/docs/current/functions/datetime.html#last_day_of_month),
  [`at_timezone`](/docs/current/functions/datetime.html#at_timezone) and 
  [`with_timezone`](/docs/current/functions/datetime.html#with_timezone).

## Security

* [Role-based access control](/docs/current/sql/create-role.html) and related commands.
* [INVOKER security mode](/docs/current/sql/create-view.html#security) for views, which allows views to be run using the permissions of the 
  current user.
* Prevent replay attacks and result hijacking in client APIs.
* JWT-based [internal communication](/docs/current/security/internal-communication.html#internal-authentication) authentication,
  which obsoletes the need to use Kerberos or certificates and greatly simplifies secure setups.
* Credential passthrough, which allows Presto to authenticate with the underlying data source with 
  credentials provided by the user running a query. This especially useful when dealing with
  Google Storage in GCP or SQL databases that manage user authentication and authorization on 
  their own.
* Impersonation for [Hive metastore](/docs/current/connector/hive.html#hive-thrift-metastore-configuration-properties).
* Support for reading and writing encrypted files in HDFS using Hadoop KMS.
* Support for [encrypting spilled data]({{site.url}}/docs/current/admin/spill.html#spill-encryption).

## Geospatial

* New geospatial functions: 
  [`ST_Points`](/docs/current/functions/geospatial.html#ST_Points), 
  [`ST_Length`](/docs/current/functions/geospatial.html#ST_Length), 
  [`ST_Area`](/docs/current/functions/geospatial.html#ST_Area), 
  [`line_interpolate_point`](/docs/current/functions/geospatial.html#line_interpolate_point) and 
  [`line_interpolate_points`](/docs/current/functions/geospatial.html#line_interpolate_points).
* `SphericalGeography` type and [related functions](/docs/current/functions/geospatial.html#to_spherical_geography) 
  to support spatial features in geographic coordinates (latitude / longitude) using a spherical model of the earth.
* Support for Google Maps Polyline format via [`to_encoded_polyline`](/docs/current/functions/geospatial.html#to_encoded_polyline)
  and [`from_encoded_polyline`](/docs/current/functions/geospatial.html#from_encoded_polyline) functions.
* [`geometry_from_hadoop_shape`](/docs/current/functions/geospatial.html#geometry_from_hadoop_shape) to decode geometry objects in 
  Spatial Framework for Hadoop representation

## Cloud Integration

* Support for Azure Data Lake Blob and ADLS Gen2 storage.
* Support for [Google Cloud Storage](/docs/current/connector/hive-gcs-tutorial.html).
* Several [performance improvements]({% post_url 2019-05-06-faster-s3-reads %}) for AWS S3.

## CLI and JDBC Driver

* JSON output format and improvements to CSV output format.
* Support and stability improvements for running the CLI and JDBC driver with Java 11.
* Improve compatibility of JDBC driver with third-party tools.
* Syntax highlighting and multi-line editing.
 
  ![](/assets/blog/2019-review/presto-cli.jpg)

## New Connectors

* [Elasticsearch](/docs/current/connector/elasticsearch.html)
* [Google Sheets](/docs/current/connector/googlesheets.html)
* [Amazon Kinesis](/docs/current/connector/kinesis.html)
* [Apache Phoenix]({% post_url 2019-06-04-phoenix-connector %})
* [MemSQL](/docs/current/connector/memsql.html)
* Apache Iceberg (preview version still under development)

## Other Improvements

[Presto Docker image](https://hub.docker.com/r/prestosql/presto) that provides an out-of-the-box single node 
  cluster with the JMX, memory, TPC-DS, and TPC-H catalogs. It can be deployed as a full cluster by 
  mounting in configuration and can be used for Kubernetes deployments.
* Support for LZ4 and Zstd compression in Parquet and ORC. LZ4 is currently the recommended algorithm for fast, lightweight
  compression, and Zstd otherwise.
* Support for insert-only Hive transactional tables and Hive bucketing v2 as part of 
  [making Presto compatible with Hive 3]({% post_url 2019-12-28-hive-3 %}).
* Improvements in `ANALYZE` statement for Hive connector.
* Support for [multiple files per bucket]({% post_url 2019-05-29-improved-hive-bucketing %}) 
  for Hive tables. This allows inserting data into bucketed tables without having to rewrite entire partitions
  and improves Presto compatibility with Hive and other tools.
* Support for upper- and mixed-case table and column names in JDBC-based connectors.
* New features and improvements in type mappings in PostgreSQL, MySQL, SQL Server and Redshift
  connectors. This includes support for PostgreSQL arrays and `timestamp with time zone` type, and 
  the ability to read columns of unsupported types.
* Improvements in [Hive compatibility with Hive version 2.3]({{site.github_repo_url}}/pull/833) 
  and [with Cloudera (CDH)'s Hive]({{site.github_repo_url}}/pull/1937).
* Connector provided view definitions, which allow connectors to generate the definition dynamically at query time. 
  For example, the connector can provide a union of two tables filtered on a disjoint time range, with the cutoff 
  time determined at resolution time.
* Lots and lots of bug fixes!

# Coming Up...

These are some of the projects that are currently in progress and are likely to land in the short term.

* Support for pushing down row dereference expressions into connectors. This will help reduce 
  the amount of data and CPU needed to process highly nested columnar formats such as ORC and Parquet.
* Extend dynamic filtering to support distributed joins and other operators. Use dynamic filters for 
  pruning partitions at runtime when querying Hive.
* [Extended Late Materialization]({{site.github_repo_url}}/pull/2418) support to queries involving 
  complex correlated subqueries.
* Finalize [Hive 3 support]({% post_url 2019-12-28-hive-3 %}).
* Improved [INSERT into partitioned tables]({{site.github_repo_url}}/pull/2358), which will help with 
  large ETL queries.
* [Improvements and features]({{site.github_repo_url}}/issues/1324) in Iceberg connector.
* [Pinot]({{site.github_repo_url}}/pull/2028) connector.
* [Oracle]({{site.github_repo_url}}/pull/1959) connector.
* [Influx]({{site.github_repo_url}}/pull/2397) connector.
* [Prometheus]({{site.github_repo_url}}/pull/2321) connector.
* [Salesforce](https://{{site.slack_fqdn}}/archives/CQT2JH4KG/p1576038838027500) connector. 
* Support for [Confluent registry in Kafka connector]({{site.github_repo_url}}/pull/2106).
* Revamp of the function registry and function resolution to support dynamically-resolved 
  functions and SQL-defined functions.
* A new [Parquet writer]({{site.github_repo_url}}/pull/2004) optimized to work efficiently 
  within Presto.

... and many, many more.